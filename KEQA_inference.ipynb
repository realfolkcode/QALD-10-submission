{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KEQA_inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Paper: [Knowledge Graph Embedding Based Question Answering](http://research.baidu.com/Public/uploads/5c1c9a58317b3.pdf)"
      ],
      "metadata": {
        "id": "tlRkXs15O9FM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and Install"
      ],
      "metadata": {
        "id": "OPf13i_aTXaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torchtext==0.3.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGXLKgEUnzw_",
        "outputId": "17964a53-fbc8-4a6e-a424-e0843f97ef1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.3.1\n",
            "  Downloading torchtext-0.3.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (1.11.0+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.3.1) (4.64.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.3.1) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.3.1) (4.2.0)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.12.0\n",
            "    Uninstalling torchtext-0.12.0:\n",
            "      Successfully uninstalled torchtext-0.12.0\n",
            "Successfully installed torchtext-0.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy[speedup]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-88ZOD7Wn5SZ",
        "outputId": "da94245b-3de8-4888-d459-aa4300f7f2cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy[speedup]\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting python-levenshtein>=0.12\n",
            "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 35.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 30 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 40 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-levenshtein>=0.12->fuzzywuzzy[speedup]) (57.4.0)\n",
            "Building wheels for collected packages: python-levenshtein\n",
            "  Building wheel for python-levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149862 sha256=c7a1b8e9c907af4b041941a2bbe8ce1d29eb596dd6bb7752d17dc3fd948b7571\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built python-levenshtein\n",
            "Installing collected packages: python-levenshtein, fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0 python-levenshtein-0.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTzEOFlefn6a",
        "outputId": "d44b5e3d-11f8-44ff-c813-6e9b16041df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KEQA_WSDM19'...\n",
            "remote: Enumerating objects: 122, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 122 (delta 6), reused 13 (delta 4), pack-reused 106\u001b[K\n",
            "Receiving objects: 100% (122/122), 54.87 KiB | 13.72 MiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/realfolkcode/KEQA_WSDM19.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd KEQA_WSDM19"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k612zLJfgaKE",
        "outputId": "d435a186-6251-40eb-978d-da9737c7abe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/KEQA_WSDM19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-1-2S-_ggvZ",
        "outputId": "c6e7b20e-d0a8-4485-e5dc-a39ed8a5f6f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fuzzywuzzy>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (0.18.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.0.2)\n",
            "Requirement already satisfied: torchtext==0.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (0.3.1)\n",
            "Collecting nltk>=3.3\n",
            "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 20.6 MB/s \n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==0.4.1 (from versions: 1.0.0, 1.0.1, 1.0.1.post2, 1.1.0, 1.2.0, 1.3.0, 1.3.1, 1.4.0, 1.5.0, 1.5.1, 1.6.0, 1.7.0, 1.7.1, 1.8.0, 1.8.1, 1.9.0, 1.9.1, 1.10.0, 1.10.1, 1.10.2, 1.11.0)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for torch==0.4.1\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download pretrained models"
      ],
      "metadata": {
        "id": "Tv92WHCVFosV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1s6PmljOR-TxVwp6a_9DCwdL-t9xbrjWq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbPU89F0Fq90",
        "outputId": "b640e42f-566b-4632-fa1f-b3a194180471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1s6PmljOR-TxVwp6a_9DCwdL-t9xbrjWq\n",
            "To: /content/KEQA_WSDM19/preprocess.zip\n",
            "100% 243M/243M [00:04<00:00, 50.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip preprocess.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g71gYtyuF1rf",
        "outputId": "829f4344-cfbb-40c8-edb8-7bc815c61f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  preprocess.zip\n",
            "   creating: preprocess/\n",
            "  inflating: preprocess/dete_best_model.pt  \n",
            "  inflating: preprocess/dete_train.txt  \n",
            "  inflating: preprocess/entity_best_model.pt  \n",
            "  inflating: preprocess/entity_train.txt  \n",
            "  inflating: preprocess/entity_valid.txt  \n",
            "  inflating: preprocess/pred_best_model.pt  \n",
            "  inflating: preprocess/pred_train.txt  \n",
            "  inflating: preprocess/pred_valid.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download SimpleQuestions dataset"
      ],
      "metadata": {
        "id": "jxTTMND0hNlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/9lxudhdfpfkihr1/data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJkhZ0xkgivb",
        "outputId": "7642a67f-5d8a-430a-a9c4-be23dbc583d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-20 19:34:56--  https://www.dropbox.com/s/9lxudhdfpfkihr1/data.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6031:18::a27d:5112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/9lxudhdfpfkihr1/data.zip [following]\n",
            "--2022-05-20 19:34:56--  https://www.dropbox.com/s/raw/9lxudhdfpfkihr1/data.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc16b7beac7d03db5c12ca76cf1f.dl.dropboxusercontent.com/cd/0/inline/Blphiz1f-QMe1vrxybHs4M_RUcxcA-LQl9HOLkpIUzccUWXhnwH5LHqsa8wZr6VEYHE4flN7JavEiN3vgyOU8ETRTiV16uL8CcqS1DZfwEHB-EGZffy58jF9Rsimr9qAcR9aHs2cs8pY9inYu5I4rKr340gFJO_XxcbQoZRaGfWpyA/file# [following]\n",
            "--2022-05-20 19:34:57--  https://uc16b7beac7d03db5c12ca76cf1f.dl.dropboxusercontent.com/cd/0/inline/Blphiz1f-QMe1vrxybHs4M_RUcxcA-LQl9HOLkpIUzccUWXhnwH5LHqsa8wZr6VEYHE4flN7JavEiN3vgyOU8ETRTiV16uL8CcqS1DZfwEHB-EGZffy58jF9Rsimr9qAcR9aHs2cs8pY9inYu5I4rKr340gFJO_XxcbQoZRaGfWpyA/file\n",
            "Resolving uc16b7beac7d03db5c12ca76cf1f.dl.dropboxusercontent.com (uc16b7beac7d03db5c12ca76cf1f.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6031:15::a27d:510f\n",
            "Connecting to uc16b7beac7d03db5c12ca76cf1f.dl.dropboxusercontent.com (uc16b7beac7d03db5c12ca76cf1f.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BlrqMLEKyHnatWX50inyB1cVHmbMWybSKLoKYsF4-cBFYjuAoy19mylbt8FyRmIz0defn_geLZN8Zcn5G4xJ_MLybg0iH4mohi3ee7gPS47lIcPgJflpCcYDY02Omg_El_bKlkP-UdaxeTKMlZRWQd1ldv-y0iA2yLFAbvnCgb8KSSPsjTR3Q_60LpeOOkBn3ZQ1WFJ-Pxd1wHfS2MOLNWdEQiakc42y4q55S-J0yIUZ9ge6qm8zEWNMGpiot_qKs9jS07vf9BBedE323E09u4S1wyn_BDGTSBlLMt-kMOlI1XCi0vBRjNDmiFU-3NlcVPYCaFNiiB7LFvp_YYj6RW04xgEu-coOS3BD3-OTLT1NPl_AeiP-yRy2OClXSNA2eSa3C-Vly1_a5-19NF_IF7DBDF2IF027PAir_-XgRzTqpA/file [following]\n",
            "--2022-05-20 19:34:57--  https://uc16b7beac7d03db5c12ca76cf1f.dl.dropboxusercontent.com/cd/0/inline2/BlrqMLEKyHnatWX50inyB1cVHmbMWybSKLoKYsF4-cBFYjuAoy19mylbt8FyRmIz0defn_geLZN8Zcn5G4xJ_MLybg0iH4mohi3ee7gPS47lIcPgJflpCcYDY02Omg_El_bKlkP-UdaxeTKMlZRWQd1ldv-y0iA2yLFAbvnCgb8KSSPsjTR3Q_60LpeOOkBn3ZQ1WFJ-Pxd1wHfS2MOLNWdEQiakc42y4q55S-J0yIUZ9ge6qm8zEWNMGpiot_qKs9jS07vf9BBedE323E09u4S1wyn_BDGTSBlLMt-kMOlI1XCi0vBRjNDmiFU-3NlcVPYCaFNiiB7LFvp_YYj6RW04xgEu-coOS3BD3-OTLT1NPl_AeiP-yRy2OClXSNA2eSa3C-Vly1_a5-19NF_IF7DBDF2IF027PAir_-XgRzTqpA/file\n",
            "Reusing existing connection to uc16b7beac7d03db5c12ca76cf1f.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 562320907 (536M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>] 536.27M  15.0MB/s    in 39s     \n",
            "\n",
            "2022-05-20 19:35:37 (13.6 MB/s) - ‘data.zip’ saved [562320907/562320907]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHwz8MzagoyC",
        "outputId": "d3902cfa-1553-48c1-c4a7-fbf9765a45d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "   creating: data/\n",
            "  inflating: data/freebase-FB5M.txt  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/data/\n",
            "  inflating: __MACOSX/data/._freebase-FB5M.txt  \n",
            "  inflating: data/freebase-FB2M.txt  \n",
            "  inflating: __MACOSX/data/._freebase-FB2M.txt  \n",
            "  inflating: data/annotated_fb_data_train.txt  \n",
            "  inflating: __MACOSX/data/._annotated_fb_data_train.txt  \n",
            "  inflating: data/annotated_fb_data_valid.txt  \n",
            "  inflating: __MACOSX/data/._annotated_fb_data_valid.txt  \n",
            "  inflating: data/annotated_fb_data_test.txt  \n",
            "  inflating: __MACOSX/data/._annotated_fb_data_test.txt  \n",
            "  inflating: data/sq_glove300d.pt    \n",
            "  inflating: __MACOSX/data/._sq_glove300d.pt  \n",
            "  inflating: data/FB5M.name.txt      \n",
            "  inflating: __MACOSX/data/._FB5M.name.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess the raw data"
      ],
      "metadata": {
        "id": "KTFYVLoIhO9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python trim_names.py -f data/freebase-FB2M.txt -n data/FB5M.name.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpXD96u2gtc2",
        "outputId": "acf71823-8b3e-450e-c90f-def85171a099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get all mids in the Freebase subset...\n",
            "line: 0\n",
            "line: 1000000\n",
            "line: 2000000\n",
            "line: 3000000\n",
            "line: 4000000\n",
            "line: 5000000\n",
            "line: 6000000\n",
            "line: 7000000\n",
            "line: 8000000\n",
            "line: 9000000\n",
            "line: 10000000\n",
            "select head entities based on questions:\n",
            "line: 0\n",
            "line: 1000000\n",
            "line: 2000000\n",
            "line: 3000000\n",
            "line: 4000000\n",
            "line: 5000000\n",
            "459763 out of 5507279 entities are selected for head\n",
            "recall of head entity selection: 0.9627001328392645\n",
            "based on selected entities filter Freebase subset\n",
            "line: 0\n",
            "line: 1000000\n",
            "line: 2000000\n",
            "line: 3000000\n",
            "line: 4000000\n",
            "line: 5000000\n",
            "line: 6000000\n",
            "line: 7000000\n",
            "Number of entities in transE_*: 647676\n",
            "Number of predicates in transE_*: 4641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embed the Knowledge Graph\n",
        "\n",
        "It takes too long time and an existing method is used. Thus, we download the Knowledge Graph Embedding directly..."
      ],
      "metadata": {
        "id": "fqi5S_xfiUey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/o5hd8lnr5c0l6hj/KGembed.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh1N1j1riDQo",
        "outputId": "49f9f56d-4a11-4c58-d797-92f40c2f5aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-20 19:40:37--  https://www.dropbox.com/s/o5hd8lnr5c0l6hj/KGembed.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/o5hd8lnr5c0l6hj/KGembed.zip [following]\n",
            "--2022-05-20 19:40:37--  https://www.dropbox.com/s/raw/o5hd8lnr5c0l6hj/KGembed.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc0330504894efccd6c1c7011e11.dl.dropboxusercontent.com/cd/0/inline/BlqqXPuqhJBpYoJc7hajtsDFw1--hSnQa9l80LG_isuBsK4VIvuOp-W6itFBgdqxNb7EVxq9JgXCSLNLw8gWJW0O-IYp-eZB6xjv_k2wC8MFIzlkBKivRUakwivU-winTPPSK_57mlfLplTvCx6JyV1Mo6uApazXih14VfHnk6IhBg/file# [following]\n",
            "--2022-05-20 19:40:38--  https://uc0330504894efccd6c1c7011e11.dl.dropboxusercontent.com/cd/0/inline/BlqqXPuqhJBpYoJc7hajtsDFw1--hSnQa9l80LG_isuBsK4VIvuOp-W6itFBgdqxNb7EVxq9JgXCSLNLw8gWJW0O-IYp-eZB6xjv_k2wC8MFIzlkBKivRUakwivU-winTPPSK_57mlfLplTvCx6JyV1Mo6uApazXih14VfHnk6IhBg/file\n",
            "Resolving uc0330504894efccd6c1c7011e11.dl.dropboxusercontent.com (uc0330504894efccd6c1c7011e11.dl.dropboxusercontent.com)... 162.125.81.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uc0330504894efccd6c1c7011e11.dl.dropboxusercontent.com (uc0330504894efccd6c1c7011e11.dl.dropboxusercontent.com)|162.125.81.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BlqL9xbbCWmxIlLQ8frYY5m7IDTWZnvrBrGs547vTodOseyVgDVZOaoiGTPluIoAMNwCRUW0NepgeIfRL9_GTNiwCGBJoySS2ve9RT_r7zKtyCXKXbzfJv5hMZsKdfetSLSztVrc1AaAB015ozZfg4dB2hjQhsLc3f5AjOdH3t2n8kS6n34VAYC7DhN-DUmxF8bjVD9CqQRe3koiN3GHB5mBsGtb3L1AkIUeBTD11z1zLsw8yG07LuvMjIUVoySmTlMgLjkN-PNzKnNse28nbDyzQo_gcLh7RrLROuyPwmMVK1dZ_XnPI-jCUsXchSlPs-dHIuU3grbQyVkFrCYgI3uvuh9mnu9Ser4WkDCu8fo6VIVfranRTwldQNlZbVPWM_k9_DRy6ENeKkLyBsaS-sgRjk1qJUNlj9cs4Kd21NZC5w/file [following]\n",
            "--2022-05-20 19:40:38--  https://uc0330504894efccd6c1c7011e11.dl.dropboxusercontent.com/cd/0/inline2/BlqL9xbbCWmxIlLQ8frYY5m7IDTWZnvrBrGs547vTodOseyVgDVZOaoiGTPluIoAMNwCRUW0NepgeIfRL9_GTNiwCGBJoySS2ve9RT_r7zKtyCXKXbzfJv5hMZsKdfetSLSztVrc1AaAB015ozZfg4dB2hjQhsLc3f5AjOdH3t2n8kS6n34VAYC7DhN-DUmxF8bjVD9CqQRe3koiN3GHB5mBsGtb3L1AkIUeBTD11z1zLsw8yG07LuvMjIUVoySmTlMgLjkN-PNzKnNse28nbDyzQo_gcLh7RrLROuyPwmMVK1dZ_XnPI-jCUsXchSlPs-dHIuU3grbQyVkFrCYgI3uvuh9mnu9Ser4WkDCu8fo6VIVfranRTwldQNlZbVPWM_k9_DRy6ENeKkLyBsaS-sgRjk1qJUNlj9cs4Kd21NZC5w/file\n",
            "Reusing existing connection to uc0330504894efccd6c1c7011e11.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 608033604 (580M) [application/zip]\n",
            "Saving to: ‘KGembed.zip’\n",
            "\n",
            "KGembed.zip         100%[===================>] 579.87M  16.3MB/s    in 38s     \n",
            "\n",
            "2022-05-20 19:41:17 (15.2 MB/s) - ‘KGembed.zip’ saved [608033604/608033604]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip KGembed.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAWyyhlgicdY",
        "outputId": "988b3bc0-6748-4015-d038-5e6a19e46b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  KGembed.zip\n",
            "   creating: KGembed/\n",
            "  inflating: KGembed/entities_emb.bin  \n",
            "   creating: __MACOSX/KGembed/\n",
            "  inflating: __MACOSX/KGembed/._entities_emb.bin  \n",
            "  inflating: KGembed/relation2id.txt  \n",
            "  inflating: __MACOSX/KGembed/._relation2id.txt  \n",
            "  inflating: KGembed/predicates_emb.bin  \n",
            "  inflating: __MACOSX/KGembed/._predicates_emb.bin  \n",
            "  inflating: KGembed/entity2id.txt   \n",
            "  inflating: __MACOSX/KGembed/._entity2id.txt  \n",
            "  inflating: __MACOSX/._KGembed      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv -f KGembed/* preprocess/"
      ],
      "metadata": {
        "id": "4_tPQ_kzifPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Head Entity Detection (HED) model (optional)\n",
        "\n",
        "train and test the model..."
      ],
      "metadata": {
        "id": "J2KyssP9ilVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_detection.py --entity_detection_mode LSTM --fix_embed --gpu 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW8yDEP_ihYY",
        "outputId": "9e90ddb7-8ec6-43c3-b8ab-7a39c349ff1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: You are using GPU for training\n",
            "Embedding match number 52251 out of 61275\n",
            "Shift model to GPU\n",
            "Namespace(batch_size=16, clip_gradient=0.6, cuda=True, dete_prefix='dete', dev_every=12000, entity_detection_mode='LSTM', epochs=30, gpu=0, hidden_size=300, label=4, log_every=2000, lr=0.0003, num_layer=2, output='preprocess/', patience=15, rnn_dropout=0.3, rnn_fc_dropout=0.3, seed=3435, train_embed=False, vector_cache='data/sq_glove300d.pt', weight_decay=0, words_dim=300, words_num=61275)\n",
            "VOCAB num 61275\n",
            "Train instance 75624\n",
            "Dev instance 10845\n",
            "Entity Type 4\n",
            "EntityDetection(\n",
            "  (embed): Embedding(61275, 300)\n",
            "  (lstm): LSTM(300, 300, num_layers=2, dropout=0.3, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (relu): ReLU()\n",
            "  (hidden2tag): Sequential(\n",
            "    (0): Linear(in_features=600, out_features=600, bias=True)\n",
            "    (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.3, inplace=False)\n",
            "    (4): Linear(in_features=600, out_features=4, bias=True)\n",
            "  )\n",
            ")\n",
            "  Time Epoch Iteration Progress    (%Epoch)   Loss         Accuracy\n",
            "     0     1         1     1/4727        0% 1.449028       0.000000%\n",
            "    30     1      2001  2001/4727       42% 0.160490      76.118191%\n",
            "    60     1      4001  4001/4727       85% 0.005421      81.025056%\n",
            "    89     2      6001  1274/4727       27% 0.060991      89.560440%\n",
            "   119     2      8001  3274/4727       69% 0.046341      90.268021%\n",
            "   148     3     10001   547/4727       12% 0.028118      92.276051%\n",
            "Dev Recall:  93.029899% Precision:  89.526253% F1 Score:  91.244455%\n",
            "   181     3     12001  2547/4727       54% 0.014454      92.422458%\n",
            "Traceback (most recent call last):\n",
            "  File \"train_detection.py\", line 143, in <module>\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/KEQA_WSDM19/entity_detection.py\", line 48, in forward\n",
            "    tags = self.hidden2tag(outputs.view(-1, outputs.size(2)))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\", line 141, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1105, in _call_impl\n",
            "    forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entity representation learning (optional)"
      ],
      "metadata": {
        "id": "hCKKpZasTsCI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_entity.py --qa_mode GRU --fix_embed --gpu 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9ehydiBkb_T",
        "outputId": "1f11d304-9d09-471a-f327-1b8d4555ad33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getting names map...\n",
            "Note: You are using GPU for training\n",
            "Word embedding match number 49580 out of 57922\n",
            "Shift model to GPU\n",
            "Namespace(batch_size=32, best_prefix='entity', clip_gradient=0.6, cuda=True, dev_every=10000, embed_dim=250, epochs=30, gpu=0, hidden_size=300, label=250, log_every=2000, lr=0.0002, num_layer=2, output='preprocess', output_channel=300, patience=10, qa_mode='GRU', rnn_dropout=0.3, rnn_fc_dropout=0.3, seed=3435, train_embed=False, vector_cache='data/sq_glove300d.pt', weight_decay=0, words_dim=300, words_num=57922)\n",
            "VOCAB num 57922\n",
            "Train instance 75903\n",
            "Dev instance 4168\n",
            "EmbedVector(\n",
            "  (embed): Embedding(57922, 300)\n",
            "  (gru): GRU(300, 300, num_layers=2, dropout=0.3, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (nonlinear): Tanh()\n",
            "  (hidden2tag): Sequential(\n",
            "    (0): Linear(in_features=600, out_features=600, bias=True)\n",
            "    (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Tanh()\n",
            "    (3): Dropout(p=0.3, inplace=False)\n",
            "    (4): Linear(in_features=600, out_features=250, bias=True)\n",
            "  )\n",
            ")\n",
            "  Time Epoch Iteration Progress    (%Epoch)   Loss\n",
            "     0     1         1     1/2372        0% 0.007883\n",
            "Traceback (most recent call last):\n",
            "  File \"train_entity.py\", line 191, in <module>\n",
            "    optimizer.step()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\", line 153, in step\n",
            "    maximize=group['maximize'])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\", line 97, in adam\n",
            "    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head preprocess/entity_train.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJSVZXyCW7KV",
        "outputId": "4eee5e70-e377-4dc3-82f4-baa376aeda54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is the book e about\t602361\n",
            "to what release does the release track cardiac arrest come from\t205641\n",
            "what country was the film the debt from\t148704\n",
            "what songs have nobuo uematsu produced ?\t319078\n",
            "who produced eve-olution ?\t80251\n",
            "which artist recorded most of us are sad ?\t219648\n",
            "what movie is produced by warner bros .\t596386\n",
            "what is don graham known as ?\t551662\n",
            "what 's there to see in columbus\t602727\n",
            "what album was tibet released on\t549114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicate representation learning (optional)"
      ],
      "metadata": {
        "id": "w1vLlPFgXAS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_pred.py --qa_mode GRU --fix_embed --gpu 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZvuAL2q2i2E",
        "outputId": "1b211111-bcf9-4592-f03e-ef153e02ca4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: You are using GPU for training\n",
            "Word embedding match number 52283 out of 62645\n",
            "Shift model to GPU\n",
            "Namespace(batch_size=32, best_prefix='pred', clip_gradient=0.6, cuda=True, dev_every=10000, embed_dim=250, epochs=30, gpu=0, hidden_size=300, label=250, log_every=2000, lr=0.0003, num_layer=2, output='preprocess', output_channel=300, patience=12, qa_mode='GRU', rnn_dropout=0.3, rnn_fc_dropout=0.3, seed=3435, train_embed=False, vector_cache='data/sq_glove300d.pt', weight_decay=0, words_dim=300, words_num=62645)\n",
            "VOCAB num 62645\n",
            "Train instance 229677\n",
            "Dev instance 10845\n",
            "EmbedVector(\n",
            "  (embed): Embedding(62645, 300)\n",
            "  (gru): GRU(300, 300, num_layers=2, dropout=0.3, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (nonlinear): Tanh()\n",
            "  (hidden2tag): Sequential(\n",
            "    (0): Linear(in_features=600, out_features=600, bias=True)\n",
            "    (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Tanh()\n",
            "    (3): Dropout(p=0.3, inplace=False)\n",
            "    (4): Linear(in_features=600, out_features=250, bias=True)\n",
            "  )\n",
            ")\n",
            "  Time Epoch Iteration Progress    (%Epoch)   Loss\n",
            "     1     1         1     1/7178        0% 0.007830\n",
            "Traceback (most recent call last):\n",
            "  File \"train_pred.py\", line 200, in <module>\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 363, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 175, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head preprocess/pred_train.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re-mx3KcXM4N",
        "outputId": "472663a3-0f0b-4c44-dec5-3538b6c8b7bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what is the book e about\t1735\n",
            "to what release does the release track cardiac arrest come from\t3227\n",
            "what country was the film the debt from\t2988\n",
            "what songs have nobuo uematsu produced ?\t3681\n",
            "who produced eve-olution ?\t2547\n",
            "which artist recorded most of us are sad ?\t321\n",
            "what movie is produced by warner bros .\t1186\n",
            "what is don graham known as ?\t2114\n",
            "what 's there to see in columbus\t872\n",
            "what album was tibet released on\t3227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "ZAPDmBTcz1z5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose the corresponding file for specific language\n",
        "\n",
        "en_questions.txt\n",
        "\n",
        "de_questions.txt\n",
        "\n",
        "ru_questions.txt\n",
        "\n",
        "zh_questions.txt"
      ],
      "metadata": {
        "id": "fYcJINQO0EaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python process_questions.py --input zh_questions.txt"
      ],
      "metadata": {
        "id": "ln-hMx1MjIWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiUltxRy0AwD",
        "outputId": "57a60b77-d784-49c1-801c-4dffb57e099a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --gpu 0 --input preprocess/processed_questions.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTf8M3dnz3AV",
        "outputId": "35f86a87-51a1-487a-d0cf-90818ebcb77a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: You are using GPU for testing\n",
            "total num of example: 394\n",
            "line: 0\n",
            "line: 1000000\n",
            "line: 2000000\n",
            "line: 3000000\n",
            "line: 4000000\n",
            "line: 5000000\n",
            "133 out of 394 nonmatching names, matching accuracy: 0.6624365482233503\n",
            "tcmalloc: large alloc 1295319040 bytes == 0xe0f36000 @  0x7fa7e01501e7 0x7fa723eeb0ce 0x7fa723f45726 0x7fa723f45b09 0x7fa723f47620 0x7fa723f47d1b 0x7fa723fe941b 0x5936cc 0x548c51 0x5127f1 0x549e0e 0x593fce 0x548ae9 0x5127f1 0x549e0e 0x593fce 0x5118f8 0x549e0e 0x593fce 0x548ae9 0x5127f1 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2 0x64fc4e 0x7fa7dfd4dc87 0x5b621a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_szTghHoQdiI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}